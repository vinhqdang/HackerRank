return( list (ret = ret))
}
if (is.null(xcl$lnL[k1]) || is.null(xcl$lnL[k2])){
# lnL may be null because of few data
cat(paste("lnL may be null because of few data\n"))
ret <- F
return( list (ret = ret))
}
# divided clusters model
lnL1 = xcl$lnL[k1]
lnL2 = xcl$lnL[k2]
ctrextrt <- rbind(xcl$centers[k1,], xcl$centers[k2,])
beta <- dist(ctrextrt) / (sqrt(xcl$detVx[k1] + xcl$detVx[k2]))
if (pr.proc) cat(paste("beta=", round (beta, digit=2), "\n"))
# if (beta > 10){
# 	# 2 clusters far apart
# 	ret <- F
# 	return( list (ret = ret))
# }
alpha <- 0.5 / as.numeric(pnorm(beta))
bicdiv <- -2 * lnL1  -2 * lnL2 + 2 * q * log(n1 + n2) - 2 * (n1 + n2) * log(alpha)
# bicdiv <- -2 * lnL1 -2 * lnL2 + 2 * q - 2 * (n1 + n2) * log(alpha) # AIC
# extract 2 clusters data
y.ok1 <- lapply(xcl$cluster, "==", k1) # 1st sub-cluster or not
y.ok2 <- lapply(xcl$cluster, "==", k2) # 2nd sub-cluster or not
# extract sub data
p = ncol(x)
clj1 <- matrix(x[as.logical(y.ok1)], ncol=p)
clj2 <- matrix(x[as.logical(y.ok2)], ncol=p)
xmgd <- rbind(clj1, clj2)
# merged cluster center
ctrmgd <- (n1 * xcl$centers[k1,] + n2 * xcl$centers[k2,]) / (n1 + n2)
lnLmgd <- lnL(xmgd, ctrmgd, ignore.covar)
bicmgd <- -2 * lnLmgd$lnL + q * log(nrow(xmgd)) # BIC
# bicmgd <- -2 * lnLmgd$lnL + q  # AIC
ret <- T
list (ret = ret, ctrmgd = ctrmgd, lnLmgd = lnLmgd$lnL, detVxmgd = lnLmgd$detVx, bicmgd = bicmgd, bicdiv = bicdiv)
}
# log-likelihood under the assumption of
# p-dimensional multivariate normal distribution.
# ignore.covar: ignore the covariance
lnL <- function(x, centers, ignore.covar=T){
x <- as.matrix(x)
p <- ncol(x)	# p-dimensional multivariate
n <- nrow(x)	# sample size
if (missing(centers))
stop("centers must be a number or a matrix")
if (n <= 2)	# few data
return(list(lnL=NA, detVx=NA))
vx <- var(x)	# var-co.var matrix
# print(x)	# for debug
if (p == 1){ # x is vector
invVx <- 1 / as.vector(vx)
detVx <- as.vector(vx)
}else{
if (ignore.covar){
invVx <- diag(1/diag(vx)) # inv. matrix when assuming diag.
detVx <- prod(diag(vx)) # det. when assuming diag.
}else{
invVx <- solve(vx) # inverse matrix of "vx"
y <- chol(vx) # Cholesky decomposition
detVx <- prod(diag(y)) # vx = t(y) %*% y, where y is triangular,
# then, det(vx) = det(t(y)) * det(y)
}
}
t1 <- -p/2 * 1.837877066 # 1.837... = log(2 * 3.1415...)
t2 <- -log(detVx) / 2
xmu <- t(apply(x, 1, "-", centers))
# print(centers)	# for debug
# print(xmu)	# for debug
# s <- 0
# for (i in 1:n)
#	s <- s + t(xmu[i,]) %*% invVx %*% xmu[i,]
if (p == 1){
s <- sum(xmu^2 * invVx)
}else{
s <- sum(apply(xmu, 1, txInvVxX, invVx=invVx))
}
t3 <- -s / 2
ll <- (t1 + t2) * n + as.numeric(t3)	# log likelihood
list(lnL=ll, detVx=detVx)
}
# function for calculation of
# t(xmu[i,]) %*% invVx %*% xmu[i,]
txInvVxX <- function(x, invVx){
t(x) %*% invVx %*% x
}
xmeans(x = rnorm(50, sd=0.3), ik = 4)
matrix(rexp(200), 10)
size <- 20             #length of random number vectors
set.seed(1)
x <- runif(size)          # generate samples from uniform distribution (0.0, 1.0)
y <-runif(size)
df <-data.frame(x,y)
df
xmeans (df, ik=4)
plot (df)
size <- 200             #length of random number vectors
set.seed(1)
x <- runif(size)          # generate samples from uniform distribution (0.0, 1.0)
y <-runif(size)
df <-data.frame(x,y)
xmeans (df, ik=4)
plot (df)
y = xmeans (df, ik=4)
y$cluster
plot (df)
setwd("~/Desktop/API_VNM_DS2_en_csv_v2/")
data = read.csv("API_VNM_DS2_en_csv_v2.csv")
x = 1684
t = 1.05
x*t^10
x*t^50
x*t^100
x*t^50
x*t^60
x*t^70
x*t^65
x*t^65
x=1:12000
y1 = log(x/1000 + 1)
plot (y1~x)
y1 = log(x/1000 + 1)/4
plot (y1~x)
x = seq(1:12000,10)
?seq
x = seq(1,12000,10)
x
y1 = log(x/1000 + 1)/4
plot (y1~x)
x = seq(1,12000,50)
y1 = log(x/1000 + 1)/4
plot (y1~x)
plot (y1~x, type = "l")
x = seq(1,12000,50)
x1 = seq (1,2000,20)
f1 = log (x1/1000 + 1)/4
plot (f1 ~ x)
plot (f1 ~ x1)
f1 = log (x1/1000 + 1)/3
plot (f1 ~ x1)
plot (f1 ~ x1)/1.234
f1 = log (x1/1000 + 1)/1.35
plot (f1 ~ x1)/1.234
plot (f1 ~ x1)
f1 = log (x1/1000 + 1)/1.46
plot (f1 ~ x1)
f1 = log (x1/1000 + 1)/1.623
plot (f1 ~ x1)
length(f1)
?runif
f1 = c(f1, rep(0.65, length(x) - length(f1)))
length(f1)
plot (f1 ~ x)
plot (f1 ~ x, type = l)
plot (f1 ~ x, type = "l")
plot (f1 ~ x, type = "l", col = "red")
f2 = f1 + runif (length(f1), max=0.1,min=-0.1)
plot (f2 ~ x, type = "l", col = "red")
f2 = f1 + rnorm (length(f1), max=0.1,min=-0.1)
?rnorm
f2 = f1 + runif (length(f1), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red")
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f1 = log (x1/1000 + 1)/1.623 + 0.18
plot (f1~x1)
plot (f1~x1, ylim=c(0,1))
f1 = log (x1/1000 + 1)/1.913 + 0.18
plot (f1~x1, ylim=c(0,1))
f1 = c(f1, rep(0.65, length(x) - length(f1)))
f2 = f1 + runif (length(f1), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f1 = log (x1/1000 + 1)/1.983 + 0.18
f1 = c(f1, rep(0.65, length(x) - length(f1)))
f2 = f1 + runif (length(f1), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/1.983 + 0.18, rep(0.65, length(x) - length(f1))) + runif (length(f1), max=0.02,min=-0.05)
f2 = c(log (x1/1000 + 1)/1.983 + 0.18, rep(0.65, 10000)) + runif (length(f1), max=0.02,min=-0.05)
f2 = c(log (x1/1000 + 1)/1.983, 0.18, rep(0.65, 10000)) + runif (length(f1), max=0.02,min=-0.05)
f2 = c(log (x1/1000 + 1)/1.983 + 0.181, rep(0.65, 10000)) + runif (length(x), max=0.02,min=-0.05)
length(x1)
f2 = c(log (x1/1000 + 1)/1.983 + 0.181, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/2.014 + 0.181, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/2.014 + 0.161, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/2.014 + 0.161, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.02,min=-0.075)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/2.014 + 0.161, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.08,min=-0.175)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/2.014 + 0.161, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.05,min=-0.1)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1), panel.first = grid())
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1), panel.first = grid(), xlab="Training steps", ylab="Accuracy")
f3 = c(log (x1/1000 + 1)/1.874 + 0.1736, rep(0.68, length(x)-length(x1))) + runif (length(x), max=0.05,min=-0.03)
plot (f3~x,add =TRUE, col = "blue")
plot (f3~x,add =TRUE, col = "blue", type = "l")
f3 = c(log (x1/1000 + 1)/1.874 + 0.1736, rep(0.72, length(x)-length(x1))) + runif (length(x), max=0.05,min=-0.03)
f3 = c(log (x1/1000 + 1)/1.874 + 0.1736, rep(0.72, length(x)-length(x1))) + runif (length(x), max=0.05,min=-0.03)
plot (f3~x,add =TRUE, col = "blue", type = "l")
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1), panel.first = grid(), xlab="Training steps", ylab="Accuracy")
lines(f3, add=TRUE)
lines(f3~x, add=TRUE)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1), panel.first = grid(), xlab="Training steps", ylab="Accuracy")
lines(f3~x, add=TRUE)
install.packages("h2o")
df = read.csv("https://goo.gl/uWbihf", sep = ";")
str(df)
df = read.csv("https://goo.gl/uWbihf", sep = ";", header = FALSE)
str(df)
library (h2o)
h2o.shutdown ()
setwd("/Users/qdang/workspace/HackerRank/indeed_ml")
df <- read.table("tfidf_200.txt")
df1 <- read.table ("tfidf_500.txt")
str(df)
str(df1)
tags = read.table("tags.txt")
str(tags)
tags = read.table("tags.txt", header = TRUE)
str(tags)
library (h2o)
?h2o.glm()
?h2o.glrm()
?h2o.glm()
4374+2920
tags = read.table("tags.txt", header = TRUE)
df <- read.table("tfidf_500.txt")
train <- df[1:4374,]
test <- df[4375:7294,]
library (h2o)
h2o.init()
i <- 1
new_df <- cbind (train, tags[[i]])
lr <- h2o.glm(x=1:ncol(df),y=(ncol(df)+1),training_frame =  as.h2o(new_df))
nrow (df)
h_train <- as.h2o (train)
h_test <- as.h2o (test)
new_df <- cbind (train, tags[[i]])
lr <- h2o.glm(x=1:ncol(df),y=(ncol(df)+1),training_frame =  h_train)
pre_lr <- h2o.predict(lr, newdata = h_train)
new_df <- cbind (train, tags[[i]][1:3274])
lr <- h2o.glm(x=1:ncol(df),y=(ncol(df)+1),training_frame =  h_train)
pre_lr <- h2o.predict(lr, newdata = h_train)
new_df <- cbind (train, tags[[i]][1:4374])
lr <- h2o.glm(x=1:ncol(df),y=(ncol(df)+1),training_frame =  h_train)
pre_lr <- h2o.predict(lr, newdata = h_train)
lr <- h2o.glm(x=1:ncol(new_df),y=(ncol(new_df)+1),training_frame =  h_train)
pre_lr <- h2o.predict(lr, newdata = h_train)
str(new_df)
str(df)
lr <- h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_lr <- h2o.predict(lr, newdata = h_test)
ncol(new_df)
h_train <- as.h2o (new_df)
lr <- h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_lr <- h2o.predict(lr, newdata = h_test)
colnames(new_df)[324]
str(new_df[[324]])
?h2o.glm
lr <- h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train,
family = "binomial")
pre_lr <- h2o.predict(lr, newdata = h_test)
pre_ld
pre_lr
h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train,
family = "binomial", nfolds = 5)
summary (tags)
str(tags)
summary (tags[[1]])
h2o.gbm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train, nfolds = 5)
4047 / (4047+328)
h2o.gbm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
lr <- h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train,
family = "binomial", balance_classes = TRUE)
lr
h2o.randomForest(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train,
balance_classes = TRUE, nfolds = 5)
h2o.randomForest(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train, nfolds = 5)
tags = read.table("tags.txt", header = TRUE)
df <- read.table("tfidf_500.txt")
train <- df[1:4375,]
test <- df[4376:7296,]
library (h2o)
h2o.init()
# h_train <- as.h2o (train)
h_test <- as.h2o (test)
final_predicts <- c()
# prediction for 12 tags
for (i in 1:12) {
new_df <- cbind (train, tags[[i]])
h_train <- as.h2o (new_df)
lr <- h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train,
family = "binomial")
pre_lr <- h2o.predict(lr, newdata = h_test)
gbm1 <- h2o.gbm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_gbm1 <- h2o.predict(gbm1, newdata = h_test)
rf1 <- h2o.randomForest(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_rf1 <- h2o.predict(rf1, newdata = h_test)
all_pre = cbind (as.vector(pre_lr$predict),
as.vector(pre_gbm1$predict),
as.vector(pre_rf1$predict))
all_pre <- data.frame(all_pre)
preds <- c()
for (j in 1:nrow(all_pre)) {
a <- all_pre[j,]
tt <- table(a)
preds <- c(preds, names(tt[which.max(tt)]))
}
final_predicts <- cbind (final_predicts, preds)
}
write.table(x=final_predicts, file = "final_predicts.txt", row.names = FALSE, col.names = FALSE)
final_predicts
tags = read.table("tags.txt", header = TRUE)
df <- read.table("tfidf_500.txt")
train <- df[1:4375,]
test <- df[4376:7296,]
library (h2o)
h2o.init()
# h_train <- as.h2o (train)
h_test <- as.h2o (test)
final_predicts <- 1:nrow(test)
# prediction for 12 tags
for (i in 1:12) {
print (paste("Column ",j))
new_df <- cbind (train, tags[[i]])
h_train <- as.h2o (new_df)
lr <- h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train,
family = "binomial")
pre_lr <- h2o.predict(lr, newdata = h_test)
gbm1 <- h2o.gbm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_gbm1 <- h2o.predict(gbm1, newdata = h_test)
rf1 <- h2o.randomForest(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_rf1 <- h2o.predict(rf1, newdata = h_test)
all_pre = cbind (as.vector(pre_lr$predict),
as.vector(pre_gbm1$predict),
as.vector(pre_rf1$predict))
all_pre <- data.frame(all_pre)
preds <- c()
for (j in 1:nrow(all_pre)) {
a <- all_pre[j,]
tt <- table(a)
preds <- c(preds, names(tt[which.max(tt)]))
}
final_predicts <- cbind (final_predicts, preds)
}
write.table(x=final_predicts, file = "final_predicts.txt", row.names = FALSE, col.names = FALSE)
tags = read.table("tags.txt", header = TRUE)
df <- read.table("tfidf_500.txt")
train <- df[1:4375,]
test <- df[4376:7296,]
library (h2o)
h2o.init()
# h_train <- as.h2o (train)
h_test <- as.h2o (test)
final_predicts <- 1:nrow(test)
# prediction for 12 tags
for (i in 1:12) {
print (paste("Column ",i))
new_df <- cbind (train, tags[[i]])
h_train <- as.h2o (new_df)
lr <- h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train,
family = "binomial")
pre_lr <- h2o.predict(lr, newdata = h_test)
gbm1 <- h2o.gbm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_gbm1 <- h2o.predict(gbm1, newdata = h_test)
rf1 <- h2o.randomForest(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_rf1 <- h2o.predict(rf1, newdata = h_test)
all_pre = cbind (as.vector(pre_lr$predict),
as.vector(pre_gbm1$predict),
as.vector(pre_rf1$predict))
all_pre <- data.frame(all_pre)
preds <- c()
for (j in 1:nrow(all_pre)) {
a <- all_pre[j,]
print (a)
tt <- table(a)
preds <- c(preds, names(tt[which.max(tt)]))
}
final_predicts <- cbind (final_predicts, preds)
}
tags = read.table("tags.txt", header = TRUE)
df <- read.table("tfidf_500.txt")
train <- df[1:4375,]
test <- df[4376:7296,]
library (h2o)
h2o.init()
# h_train <- as.h2o (train)
h_test <- as.h2o (test)
final_predicts <- 1:nrow(test)
# prediction for 12 tags
for (i in 1:12) {
print (paste("Column ",i))
new_df <- cbind (train, tags[[i]])
h_train <- as.h2o (new_df)
lr <- h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train,
family = "binomial")
pre_lr <- h2o.predict(lr, newdata = h_test)
gbm1 <- h2o.gbm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_gbm1 <- h2o.predict(gbm1, newdata = h_test)
rf1 <- h2o.randomForest(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_rf1 <- h2o.predict(rf1, newdata = h_test)
all_pre = cbind (as.vector(pre_lr$predict),
as.vector(pre_gbm1$predict),
as.vector(pre_rf1$predict))
all_pre <- data.frame(all_pre)
preds <- c()
for (j in 1:nrow(all_pre)) {
a <- all_pre[j,]
print (a)
tt <- table(a)
print (tt)
print (names(tt[which.max(tt)]))
print ("--")
preds <- c(preds, names(tt[which.max(tt)]))
}
final_predicts <- cbind (final_predicts, preds)
}
tags = read.table("tags.txt", header = TRUE)
df <- read.table("tfidf_500.txt")
train <- df[1:4375,]
test <- df[4376:7296,]
library (h2o)
h2o.init()
# h_train <- as.h2o (train)
h_test <- as.h2o (test)
final_predicts <- 1:nrow(test)
# prediction for 12 tags
for (i in 1:12) {
print (paste("Column ",i))
new_df <- cbind (train, tags[[i]])
h_train <- as.h2o (new_df)
lr <- h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train,
family = "binomial")
pre_lr <- h2o.predict(lr, newdata = h_test)
gbm1 <- h2o.gbm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_gbm1 <- h2o.predict(gbm1, newdata = h_test)
rf1 <- h2o.randomForest(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_rf1 <- h2o.predict(rf1, newdata = h_test)
all_pre = cbind (as.vector(pre_lr$predict),
as.vector(pre_gbm1$predict),
as.vector(pre_rf1$predict))
all_pre <- data.frame(all_pre)
preds <- c()
for (j in 1:nrow(all_pre)) {
a <- all_pre[j,]
print (a)
tt <- table(as.vector(a))
print (tt)
print (names(tt[which.max(tt)]))
print ("--")
preds <- c(preds, names(tt[which.max(tt)]))
}
final_predicts <- cbind (final_predicts, preds)
}
all_pre
alL_pre[1,]
all_pre[1,]
a = all_pre[1,]
table (a)
as.vector(a)
as.matrix(all_pre)[1,]
as.matrix(all_pre[1])[1,]
as.matrix(all_pre[1])
a
sum(a==True)
sum(a==TRUE)
sum(a==FALSE)
a==FALSE
a=="False"
sum (a=="True")
sum (a=="False")
res = (sum(a=="True") > 2)
res
tags = read.table("tags.txt", header = TRUE)
df <- read.table("tfidf_500.txt")
train <- df[1:4375,]
test <- df[4376:7296,]
library (h2o)
h2o.init()
# h_train <- as.h2o (train)
h_test <- as.h2o (test)
final_predicts <- 1:nrow(test)
# prediction for 12 tags
for (i in 1:12) {
print (paste("Column ",i))
new_df <- cbind (train, tags[[i]])
h_train <- as.h2o (new_df)
lr <- h2o.glm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train,
family = "binomial")
pre_lr <- h2o.predict(lr, newdata = h_test)
gbm1 <- h2o.gbm(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_gbm1 <- h2o.predict(gbm1, newdata = h_test)
rf1 <- h2o.randomForest(x=1:(ncol(new_df)-1),y=ncol(new_df),training_frame =  h_train)
pre_rf1 <- h2o.predict(rf1, newdata = h_test)
all_pre = cbind (as.vector(pre_lr$predict),
as.vector(pre_gbm1$predict),
as.vector(pre_rf1$predict))
all_pre <- data.frame(all_pre)
preds <- c()
for (j in 1:nrow(all_pre)) {
a <- all_pre[j,]
res = (sum(a=="True") >= 2)
preds <- c(preds, res)
}
final_predicts <- cbind (final_predicts, preds)
}
write.table(x=final_predicts, file = "final_predicts.txt", row.names = FALSE, col.names = FALSE)
x <- read.table("tfidf_500.txt")
ncol (df)
ncol(x)
